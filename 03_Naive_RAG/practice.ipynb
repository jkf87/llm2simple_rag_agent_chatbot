{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì„¹ì…˜ 3: Naive RAG ì´í•´ ë° êµ¬í˜„\n",
    "\n",
    "## ì‹¤ìŠµ ëª©í‘œ\n",
    "- RAG íŒŒì´í”„ë¼ì¸ ì „ì²´ êµ¬í˜„\n",
    "- ë¬¸ì„œ ê¸°ë°˜ Q&A ì‹œìŠ¤í…œ ë§Œë“¤ê¸°\n",
    "- LLMì˜ í™˜ê° ë¬¸ì œë¥¼ RAGë¡œ í•´ê²°\n",
    "\n",
    "## ì‚¬ìš© ëª¨ë¸\n",
    "- **Google Gemini 2.5 Flash Lite** (ë¬´ë£Œ, Rate Limit íšŒí”¼ìš© ê¶Œì¥)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install langchain langchain-google-genai langchain-community chromadb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# LangChain ê´€ë ¨\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key ì„¤ì •\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    GOOGLE_API_KEY = getpass(\"Google API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "print(\"API Key ì„¤ì • ì™„ë£Œ!\")\n",
    "print(\"API Key ë°œê¸‰: https://aistudio.google.com/app/apikey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ìƒ˜í”Œ ë¬¸ì„œ ì¤€ë¹„\n",
    "\n",
    "ì‹¤ìŠµìš© í•™êµ ê·œì¹™ ë¬¸ì„œë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ í•™êµ ê·œì¹™ ë¬¸ì„œ\n",
    "school_rules = \"\"\"\n",
    "# ì„œìš¸AIê³ ë“±í•™êµ í•™ì¹™\n",
    "\n",
    "## ì œ1ì¥ ë“±êµ ë° ì¶œì„\n",
    "\n",
    "ì œ1ì¡° (ë“±êµì‹œê°„)\n",
    "1. ë³¸êµì˜ ì •ê·œ ë“±êµ ì‹œê°„ì€ ì˜¤ì „ 8ì‹œ 20ë¶„ì´ë‹¤.\n",
    "2. 8ì‹œ 30ë¶„ì— ì¡°íšŒë¥¼ ì‹œì‘í•˜ë¯€ë¡œ 8ì‹œ 25ë¶„ê¹Œì§€ëŠ” êµì‹¤ì— ì°©ì„í•´ì•¼ í•œë‹¤.\n",
    "3. 8ì‹œ 30ë¶„ ì´í›„ ë“±êµ ì‹œ ì§€ê°ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.\n",
    "\n",
    "ì œ2ì¡° (ì¡°í‡´ ë° ì™¸ì¶œ)\n",
    "1. ì¡°í‡´ ë° ì™¸ì¶œ ì‹œì—ëŠ” ë°˜ë“œì‹œ ë‹´ì„ì„ ìƒë‹˜ì˜ í—ˆê°€ë¥¼ ë°›ì•„ì•¼ í•œë‹¤.\n",
    "2. ì¡°í‡´/ì™¸ì¶œ ì‹ ì²­ì„œë¥¼ ì‘ì„±í•˜ì—¬ êµë¬´ì‹¤ì— ì œì¶œí•œë‹¤.\n",
    "3. ë³´í˜¸ì ë™ì˜ê°€ í•„ìš”í•œ ê²½ìš° í•™êµì—ì„œ ì—°ë½ì„ ì·¨í•œë‹¤.\n",
    "\n",
    "ì œ3ì¡° (ê²°ì„)\n",
    "1. ê²°ì„ ì‹œì—ëŠ” ë‹¹ì¼ ì˜¤ì „ 9ì‹œê¹Œì§€ í•™êµì— ì—°ë½í•´ì•¼ í•œë‹¤.\n",
    "2. ê²°ì„ ì‚¬ìœ ì„œëŠ” ë“±êµ í›„ 3ì¼ ì´ë‚´ì— ì œì¶œí•œë‹¤.\n",
    "3. ë¬´ë‹¨ê²°ì„ 3íšŒ ì‹œ í•™ë¶€ëª¨ ìƒë‹´ì„ ì‹¤ì‹œí•œë‹¤.\n",
    "\n",
    "## ì œ2ì¥ ë³µì¥ ê·œì •\n",
    "\n",
    "ì œ4ì¡° (êµë³µ)\n",
    "1. ë“±êµ ì‹œì—ëŠ” ë°˜ë“œì‹œ ì •ê·œ êµë³µì„ ì°©ìš©í•œë‹¤.\n",
    "2. í•˜ë³µ ê¸°ê°„: 5ì›” 1ì¼ ~ 9ì›” 30ì¼\n",
    "3. ë™ë³µ ê¸°ê°„: 10ì›” 1ì¼ ~ 4ì›” 30ì¼\n",
    "4. ì²´ìœ¡ë³µì€ ì²´ìœ¡ ìˆ˜ì—… ì‹œê°„ì—ë§Œ ì°©ìš©í•œë‹¤.\n",
    "\n",
    "ì œ5ì¡° (ë‘ë°œ ê·œì •)\n",
    "1. ë‘ë°œì€ ë‹¨ì •í•˜ê²Œ ìœ ì§€í•œë‹¤.\n",
    "2. ì—¼ìƒ‰ ë° íŒŒë§ˆëŠ” ê¸ˆì§€í•œë‹¤.\n",
    "3. ë¨¸ë¦¬ ì¥ì‹í’ˆì€ í™”ë ¤í•˜ì§€ ì•Šì€ ê²ƒë§Œ í—ˆìš©í•œë‹¤.\n",
    "\n",
    "## ì œ3ì¥ ê¸‰ì‹ ë° ì ì‹¬ì‹œê°„\n",
    "\n",
    "ì œ6ì¡° (ê¸‰ì‹)\n",
    "1. ì ì‹¬ ê¸‰ì‹ ì‹œê°„ì€ 12ì‹œ 30ë¶„ë¶€í„° 13ì‹œ 20ë¶„ê¹Œì§€ì´ë‹¤.\n",
    "2. ê¸‰ì‹ì‹¤ì—ì„œëŠ” ì¡°ìš©íˆ ì‹ì‚¬í•œë‹¤.\n",
    "3. ë°°ì‹ ìˆœì„œëŠ” í•™ë…„ë³„ë¡œ ì •í•´ì§„ ìˆœì„œë¥¼ ë”°ë¥¸ë‹¤.\n",
    "   - 1í•™ë…„: 12:30 ~ 12:50\n",
    "   - 2í•™ë…„: 12:50 ~ 13:10\n",
    "   - 3í•™ë…„: 13:10 ~ 13:30\n",
    "\n",
    "ì œ7ì¡° (ì ì‹¬ì‹œê°„ í™œë™)\n",
    "1. ì ì‹¬ì‹œê°„ì—ëŠ” ë„ì„œê´€, ìš´ë™ì¥, ë™ì•„ë¦¬ì‹¤ì„ ì´ìš©í•  ìˆ˜ ìˆë‹¤.\n",
    "2. êµì‹¤ ë°– í™œë™ ì‹œ í•™ìƒì¦ì„ íœ´ëŒ€í•œë‹¤.\n",
    "\n",
    "## ì œ4ì¥ íœ´ëŒ€í° ì‚¬ìš©\n",
    "\n",
    "ì œ8ì¡° (íœ´ëŒ€í° ê´€ë¦¬)\n",
    "1. ë“±êµ ì‹œ ë‹´ì„ì„ ìƒë‹˜ì—ê²Œ íœ´ëŒ€í°ì„ ì œì¶œí•œë‹¤.\n",
    "2. íœ´ëŒ€í°ì€ í•˜êµ ì‹œì— ë°˜í™˜ë°›ëŠ”ë‹¤.\n",
    "3. ìˆ˜ì—… ì¤‘ íœ´ëŒ€í° ì‚¬ìš© ì ë°œ ì‹œ 1ì£¼ì¼ê°„ ì••ìˆ˜í•œë‹¤.\n",
    "\n",
    "## ì œ5ì¥ ì‹œí—˜ ë° í‰ê°€\n",
    "\n",
    "ì œ9ì¡° (ì •ê¸°ê³ ì‚¬)\n",
    "1. ì¤‘ê°„ê³ ì‚¬: 4ì›”, 10ì›”\n",
    "2. ê¸°ë§ê³ ì‚¬: 7ì›”, 12ì›”\n",
    "3. ì‹œí—˜ ì¤‘ ë¶€ì •í–‰ìœ„ ì ë°œ ì‹œ í•´ë‹¹ ê³¼ëª© 0ì  ì²˜ë¦¬í•œë‹¤.\n",
    "\n",
    "ì œ10ì¡° (ìˆ˜í–‰í‰ê°€)\n",
    "1. ìˆ˜í–‰í‰ê°€ëŠ” ê° êµê³¼ ë‹´ë‹¹ ì„ ìƒë‹˜ì˜ ê³„íšì— ë”°ë¥¸ë‹¤.\n",
    "2. ìˆ˜í–‰í‰ê°€ ë¯¸ì œì¶œ ì‹œ 0ì  ì²˜ë¦¬í•œë‹¤.\n",
    "3. ê²°ì‹œ ì‹œì—ëŠ” ì¶”í›„ ë³„ë„ í‰ê°€ë¥¼ ì‹¤ì‹œí•œë‹¤.\n",
    "\n",
    "## ì œ6ì¥ ë°©ê³¼í›„ í™œë™\n",
    "\n",
    "ì œ11ì¡° (ë°©ê³¼í›„ í•™êµ)\n",
    "1. ë°©ê³¼í›„ ìˆ˜ì—…ì€ 15ì‹œ 30ë¶„ë¶€í„° ì‹œì‘í•œë‹¤.\n",
    "2. ì‹ ì²­ì€ ë§¤ í•™ê¸° ì´ˆì— ì˜¨ë¼ì¸ìœ¼ë¡œ ì§„í–‰í•œë‹¤.\n",
    "3. ì·¨ì†ŒëŠ” ìˆ˜ì—… ì‹œì‘ 1ì£¼ì¼ ì „ê¹Œì§€ ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "ì œ12ì¡° (ë™ì•„ë¦¬ í™œë™)\n",
    "1. ì •ê·œ ë™ì•„ë¦¬ í™œë™ì€ ë§¤ì£¼ ê¸ˆìš”ì¼ 6-7êµì‹œì— ì§„í–‰í•œë‹¤.\n",
    "2. ë™ì•„ë¦¬ ê°œì„¤ ì¡°ê±´: ìµœì†Œ 10ëª… ì´ìƒì˜ í•™ìƒ, ì§€ë„êµì‚¬ 1ëª…\n",
    "3. ë™ì•„ë¦¬ ê°€ì…ì€ 1í•™ë…„ 3ì›”ì— ì§„í–‰í•œë‹¤.\n",
    "\n",
    "## ì œ7ì¥ ìƒë²Œì  ì œë„\n",
    "\n",
    "ì œ13ì¡° (ìƒì )\n",
    "1. ë´‰ì‚¬í™œë™ 1ì‹œê°„ë‹¹ ìƒì  1ì  ë¶€ì—¬\n",
    "2. ì„ í–‰ í‘œì°½ ì‹œ ìƒì  5ì  ë¶€ì—¬\n",
    "3. êµë‚´ ëŒ€íšŒ ì…ìƒ ì‹œ ìƒì  3~10ì  ë¶€ì—¬\n",
    "\n",
    "ì œ14ì¡° (ë²Œì )\n",
    "1. ì§€ê° 1íšŒ: ë²Œì  1ì \n",
    "2. ë¬´ë‹¨ê²°ì„ 1íšŒ: ë²Œì  3ì \n",
    "3. ìˆ˜ì—… ë°©í•´ 1íšŒ: ë²Œì  2ì \n",
    "4. ë²Œì  10ì  ëˆ„ì  ì‹œ í•™ë¶€ëª¨ ìƒë‹´\n",
    "5. ë²Œì  20ì  ëˆ„ì  ì‹œ êµë‚´ ë´‰ì‚¬\n",
    "\n",
    "## ë¶€ì¹™\n",
    "\n",
    "1. ì´ í•™ì¹™ì€ 2024ë…„ 3ì›” 1ì¼ë¶€í„° ì‹œí–‰í•œë‹¤.\n",
    "2. í•™ì¹™ì— ëª…ì‹œë˜ì§€ ì•Šì€ ì‚¬í•­ì€ í•™êµ ìš´ì˜ìœ„ì›íšŒì—ì„œ ê²°ì •í•œë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "print(\"í•™êµ ê·œì¹™ ë¬¸ì„œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"ë¬¸ì„œ ê¸¸ì´: {len(school_rules)}ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„\n",
    "\n",
    "### Step 1: ë¬¸ì„œ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document ê°ì²´ë¡œ ë³€í™˜\n",
    "documents = [Document(page_content=school_rules, metadata={\"source\": \"school_rules\"})]\n",
    "\n",
    "print(f\"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(documents)}\")\n",
    "print(f\"ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {documents[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: ë¬¸ì„œ ë¶„í•  (Chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,       # ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜\n",
    "    chunk_overlap=50,     # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ë¶„í• \n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
    "print(\"\\n--- ì²­í¬ ì˜ˆì‹œ ---\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\n[ì²­í¬ {i+1}]\")\n",
    "    print(chunk.page_content)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: ì„ë² ë”© ë° Vector DB ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google ì„ë² ë”© ëª¨ë¸ ì„¤ì • (ë¬´ë£Œ)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "# ì„ë² ë”© í…ŒìŠ¤íŠ¸\n",
    "test_text = \"ë“±êµ ì‹œê°„ì´ ëª‡ ì‹œì¸ê°€ìš”?\"\n",
    "test_vector = embeddings.embed_query(test_text)\n",
    "\n",
    "print(f\"ì„ë² ë”© ë²¡í„° ì°¨ì›: {len(test_vector)}\")\n",
    "print(f\"ë²¡í„° ì¼ë¶€: {test_vector[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma Vector DBì— ì €ì¥\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_school_rules\"  # ë¡œì»¬ì— ì €ì¥\n",
    ")\n",
    "\n",
    "print(f\"Vector DB ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ìœ¼ë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰\n",
    "query = \"ë“±êµ ì‹œê°„ì´ ëª‡ ì‹œì¸ê°€ìš”?\"\n",
    "\n",
    "# ìƒìœ„ 3ê°œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰\n",
    "relevant_docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"ì§ˆë¬¸: {query}\")\n",
    "print(\"\\n--- ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ ---\")\n",
    "for i, doc in enumerate(relevant_docs):\n",
    "    print(f\"\\n[ë¬¸ì„œ {i+1}]\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰\n",
    "results_with_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "print(f\"ì§ˆë¬¸: {query}\")\n",
    "print(\"\\n--- ìœ ì‚¬ë„ ì ìˆ˜ ---\")\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"\\nì ìˆ˜: {score:.4f} (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)\")\n",
    "    print(f\"ë‚´ìš©: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: RAG ì²´ì¸ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini LLM ì„¤ì • (ë¬´ë£Œ)\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",  # Rate Limit íšŒí”¼ìš© ëª¨ë¸\n",
    "    temperature=0,  # ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "# Retriever ì„¤ì •\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # ìƒìœ„ 3ê°œ ë¬¸ì„œ ê²€ìƒ‰\n",
    ")\n",
    "\n",
    "# RAG ì²´ì¸ ìƒì„±\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # ëª¨ë“  ë¬¸ì„œë¥¼ í•œë²ˆì— í”„ë¡¬í”„íŠ¸ì— í¬í•¨\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True  # ì°¸ì¡° ë¬¸ì„œë„ ë°˜í™˜\n",
    ")\n",
    "\n",
    "print(\"RAG ì²´ì¸ ì„¤ì • ì™„ë£Œ! (Gemini 2.5 Flash Lite ì‚¬ìš©)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: ì§ˆë¬¸-ë‹µë³€ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ í•¨ìˆ˜\n",
    "def ask_question(question):\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    \n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"\\nA: {result['result']}\")\n",
    "    print(\"\\n--- ì°¸ì¡° ë¬¸ì„œ ---\")\n",
    "    for i, doc in enumerate(result['source_documents'][:2]):\n",
    "        print(f\"[{i+1}] {doc.page_content[:100]}...\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
    "questions = [\n",
    "    \"ë“±êµ ì‹œê°„ì´ ëª‡ ì‹œì¸ê°€ìš”?\",\n",
    "    \"ì ì‹¬ ê¸‰ì‹ ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”?\",\n",
    "    \"íœ´ëŒ€í° ì‚¬ìš© ê·œì •ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
    "    \"ë™ì•„ë¦¬ í™œë™ì€ ì–¸ì œ í•˜ë‚˜ìš”?\",\n",
    "    \"ë²Œì ì€ ì–´ë–¤ ê²½ìš°ì— ë°›ë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    ask_question(q)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. RAG vs ì¼ë°˜ LLM ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¼ë°˜ LLMì—ê²Œ ê°™ì€ ì§ˆë¬¸ (Gemini ì‚¬ìš©)\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-lite')  # Rate Limit íšŒí”¼ìš© ëª¨ë¸\n",
    "\n",
    "def ask_without_rag(question):\n",
    "    response = model.generate_content(question)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„êµ í…ŒìŠ¤íŠ¸\n",
    "test_question = \"ì„œìš¸AIê³ ë“±í•™êµì˜ ì ì‹¬ ê¸‰ì‹ ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”?\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"[ì¼ë°˜ LLMì˜ ë‹µë³€]\")\n",
    "print(ask_without_rag(test_question))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"[RAGë¥¼ ì‚¬ìš©í•œ ë‹µë³€]\")\n",
    "result = qa_chain.invoke({\"query\": test_question})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Streamlitìœ¼ë¡œ RAG ì±—ë´‡ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile rag_chatbot.py\n",
    "\"\"\"\n",
    "RAG ê¸°ë°˜ í•™êµ ê·œì¹™ Q&A ì±—ë´‡ (Gemini ë²„ì „)\n",
    "ì‹¤í–‰: streamlit run rag_chatbot.py\n",
    "\"\"\"\n",
    "import streamlit as st\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "\n",
    "st.set_page_config(page_title=\"í•™êµ ê·œì¹™ Q&A\", page_icon=\"ğŸ“š\")\n",
    "\n",
    "st.title(\"í•™êµ ê·œì¹™ Q&A ì±—ë´‡ ğŸ“š\")\n",
    "st.caption(\"í•™êµ ê·œì¹™ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! (Gemini ë¬´ë£Œ)\")\n",
    "\n",
    "# ìƒ˜í”Œ í•™êµ ê·œì¹™\n",
    "SCHOOL_RULES = '''\n",
    "# ì„œìš¸AIê³ ë“±í•™êµ í•™ì¹™\n",
    "\n",
    "ì œ1ì¡° (ë“±êµì‹œê°„)\n",
    "1. ë³¸êµì˜ ì •ê·œ ë“±êµ ì‹œê°„ì€ ì˜¤ì „ 8ì‹œ 20ë¶„ì´ë‹¤.\n",
    "2. 8ì‹œ 30ë¶„ì— ì¡°íšŒë¥¼ ì‹œì‘í•˜ë¯€ë¡œ 8ì‹œ 25ë¶„ê¹Œì§€ëŠ” êµì‹¤ì— ì°©ì„í•´ì•¼ í•œë‹¤.\n",
    "\n",
    "ì œ6ì¡° (ê¸‰ì‹)\n",
    "1. ì ì‹¬ ê¸‰ì‹ ì‹œê°„ì€ 12ì‹œ 30ë¶„ë¶€í„° 13ì‹œ 20ë¶„ê¹Œì§€ì´ë‹¤.\n",
    "2. 1í•™ë…„: 12:30~12:50, 2í•™ë…„: 12:50~13:10, 3í•™ë…„: 13:10~13:30\n",
    "\n",
    "ì œ8ì¡° (íœ´ëŒ€í° ê´€ë¦¬)\n",
    "1. ë“±êµ ì‹œ ë‹´ì„ì„ ìƒë‹˜ì—ê²Œ íœ´ëŒ€í°ì„ ì œì¶œí•œë‹¤.\n",
    "2. íœ´ëŒ€í°ì€ í•˜êµ ì‹œì— ë°˜í™˜ë°›ëŠ”ë‹¤.\n",
    "\n",
    "ì œ12ì¡° (ë™ì•„ë¦¬ í™œë™)\n",
    "1. ì •ê·œ ë™ì•„ë¦¬ í™œë™ì€ ë§¤ì£¼ ê¸ˆìš”ì¼ 6-7êµì‹œì— ì§„í–‰í•œë‹¤.\n",
    "\n",
    "ì œ14ì¡° (ë²Œì )\n",
    "1. ì§€ê° 1íšŒ: ë²Œì  1ì \n",
    "2. ë¬´ë‹¨ê²°ì„ 1íšŒ: ë²Œì  3ì \n",
    "3. ë²Œì  10ì  ëˆ„ì  ì‹œ í•™ë¶€ëª¨ ìƒë‹´\n",
    "'''\n",
    "\n",
    "# ì‚¬ì´ë“œë°”\n",
    "with st.sidebar:\n",
    "    api_key = st.text_input(\"Google API Key\", type=\"password\",\n",
    "                           help=\"https://aistudio.google.com/app/apikey\")\n",
    "    \n",
    "    if st.button(\"ëŒ€í™” ì´ˆê¸°í™”\"):\n",
    "        st.session_state.messages = []\n",
    "        st.rerun()\n",
    "    \n",
    "    st.divider()\n",
    "    st.markdown(\"### ì§ˆë¬¸ ì˜ˆì‹œ\")\n",
    "    st.markdown(\"- ë“±êµ ì‹œê°„ì´ ëª‡ ì‹œì¸ê°€ìš”?\")\n",
    "    st.markdown(\"- ì ì‹¬ ê¸‰ì‹ì€ ì–¸ì œì¸ê°€ìš”?\")\n",
    "    st.markdown(\"- íœ´ëŒ€í° ê·œì •ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\")\n",
    "\n",
    "# RAG ì´ˆê¸°í™” í•¨ìˆ˜\n",
    "@st.cache_resource\n",
    "def init_rag(_api_key):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = _api_key\n",
    "    \n",
    "    # ë¬¸ì„œ ì¤€ë¹„\n",
    "    documents = [Document(page_content=SCHOOL_RULES)]\n",
    "    \n",
    "    # ì²­í¬ ë¶„í• \n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=30)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    \n",
    "    # Vector DB ìƒì„± (Google ì„ë² ë”©)\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"models/embedding-001\",\n",
    "        google_api_key=_api_key\n",
    "    )\n",
    "    vectorstore = Chroma.from_documents(chunks, embeddings)\n",
    "    \n",
    "    # QA Chain ìƒì„± (Gemini)\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0,\n",
    "        google_api_key=_api_key\n",
    "    )\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    \n",
    "    return qa_chain\n",
    "\n",
    "# ë©”ì‹œì§€ ì´ˆê¸°í™”\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# ì´ì „ ë©”ì‹œì§€ í‘œì‹œ\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.markdown(msg[\"content\"])\n",
    "\n",
    "# ìƒˆ ë©”ì‹œì§€ ì²˜ë¦¬\n",
    "if prompt := st.chat_input(\"í•™êµ ê·œì¹™ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”...\"):\n",
    "    if not api_key:\n",
    "        st.error(\"API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!\")\n",
    "        st.stop()\n",
    "    \n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "    \n",
    "    # RAG ì‘ë‹µ ìƒì„±\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"ê²€ìƒ‰ ì¤‘...\"):\n",
    "            try:\n",
    "                qa_chain = init_rag(api_key)\n",
    "                result = qa_chain.invoke({\"query\": prompt})\n",
    "                \n",
    "                answer = result['result']\n",
    "                st.markdown(answer)\n",
    "                \n",
    "                # ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ\n",
    "                with st.expander(\"ì°¸ì¡° ë¬¸ì„œ ë³´ê¸°\"):\n",
    "                    for i, doc in enumerate(result['source_documents']):\n",
    "                        st.markdown(f\"**[ë¬¸ì„œ {i+1}]**\")\n",
    "                        st.markdown(doc.page_content)\n",
    "                        st.divider()\n",
    "                \n",
    "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "                \n",
    "            except Exception as e:\n",
    "                st.error(f\"ì˜¤ë¥˜: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. ì‹¤ìŠµ ê³¼ì œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê³¼ì œ 1: ë‚˜ë§Œì˜ ë¬¸ì„œë¡œ RAG ë§Œë“¤ê¸°\n",
    "\n",
    "ì•„ë˜ì— ë³¸ì¸ë§Œì˜ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ê³  RAG ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚˜ë§Œì˜ ë¬¸ì„œ ì‘ì„± (ì˜ˆ: ê²Œì„ ê³µëµ, ìš”ë¦¬ ë ˆì‹œí”¼, ì·¨ë¯¸ ì •ë³´ ë“±)\n",
    "my_document = \"\"\"\n",
    "# ì—¬ê¸°ì— ë³¸ì¸ë§Œì˜ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "# ë§ˆì¸í¬ë˜í”„íŠ¸ ì´ˆë³´ì ê°€ì´ë“œ\n",
    "\n",
    "## ì²«ë‚  ìƒì¡´\n",
    "1. ë‚˜ë¬´ë¥¼ ë¨¼ì € ì±„ì§‘í•©ë‹ˆë‹¤.\n",
    "2. ì‘ì—…ëŒ€ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# TODO: ìœ„ ë¬¸ì„œë¡œ RAG ì‹œìŠ¤í…œ êµ¬í˜„\n",
    "# 1. Document ê°ì²´ ìƒì„±\n",
    "# 2. ì²­í¬ ë¶„í• \n",
    "# 3. Vector DB ì €ì¥\n",
    "# 4. QA Chain ìƒì„±\n",
    "# 5. ì§ˆë¬¸-ë‹µë³€ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê³¼ì œ 2: íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œí•˜ê¸°\n",
    "\n",
    "í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ì„œ RAG ì‹œìŠ¤í…œì— ì ìš©í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì¼ ë¡œë“œ ì˜ˆì‹œ\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# loader = TextLoader(\"my_document.txt\", encoding=\"utf-8\")\n",
    "# documents = loader.load()\n",
    "\n",
    "# TODO: íŒŒì¼ì„ ë¡œë“œí•˜ê³  RAG ì‹œìŠ¤í…œ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. ëª¨ë‘  í™œë™\n",
    "\n",
    "### \"RAGê°€ í•„ìš”í•œ ì£¼ì œ ì„ ì •í•˜ê¸°\"\n",
    "\n",
    "ì¡°ë³„ë¡œ ë‹¤ìŒì„ ë…¼ì˜í•˜ê³  ì‘ì„±í•´ë³´ì„¸ìš”:\n",
    "\n",
    "1. **ì£¼ì œ**: ì–´ë–¤ RAG ì‹œìŠ¤í…œì„ ë§Œë“¤ê³  ì‹¶ì€ê°€?\n",
    "2. **ë¬¸ì„œ**: ì–´ë–¤ ë¬¸ì„œê°€ í•„ìš”í•œê°€?\n",
    "3. **ì§ˆë¬¸ ì˜ˆì‹œ**: ì‚¬ìš©ìê°€ í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì€?\n",
    "4. **ê¸°ëŒ€ íš¨ê³¼**: ì´ ì‹œìŠ¤í…œì˜ ì¥ì ì€?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë‘  í™œë™ ê²°ê³¼ ì‘ì„±\n",
    "group_project = {\n",
    "    \"íŒ€ëª…\": \"\",\n",
    "    \"ì£¼ì œ\": \"\",\n",
    "    \"í•„ìš” ë¬¸ì„œ\": [],\n",
    "    \"ì§ˆë¬¸ ì˜ˆì‹œ\": [],\n",
    "    \"ê¸°ëŒ€ íš¨ê³¼\": \"\"\n",
    "}\n",
    "\n",
    "# ì˜ˆì‹œ\n",
    "example_project = {\n",
    "    \"íŒ€ëª…\": \"ë§›ìˆëŠ” AI\",\n",
    "    \"ì£¼ì œ\": \"í•œì‹ ìš”ë¦¬ ë ˆì‹œí”¼ Q&A ë´‡\",\n",
    "    \"í•„ìš” ë¬¸ì„œ\": [\"ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼\", \"ëœì¥ì°Œê°œ ë ˆì‹œí”¼\", \"ë¶ˆê³ ê¸° ë ˆì‹œí”¼\"],\n",
    "    \"ì§ˆë¬¸ ì˜ˆì‹œ\": [\"ê¹€ì¹˜ì°Œê°œì— ë­˜ ë„£ì–´ì•¼ í•´?\", \"ë¶ˆê³ ê¸° ì–‘ë… ë¹„ìœ¨ì´ ì–´ë–»ê²Œ ë¼?\"],\n",
    "    \"ê¸°ëŒ€ íš¨ê³¼\": \"ìš”ë¦¬ ì´ˆë³´ìë„ ì‰½ê²Œ í•œì‹ ìš”ë¦¬ ê°€ëŠ¥\"\n",
    "}\n",
    "\n",
    "print(\"ì˜ˆì‹œ í”„ë¡œì íŠ¸:\")\n",
    "for k, v in example_project.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì •ë¦¬\n",
    "\n",
    "### ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©\n",
    "\n",
    "1. **RAG ê°œë…**: ê²€ìƒ‰ + ìƒì„±ìœ¼ë¡œ LLM í•œê³„ ê·¹ë³µ\n",
    "2. **íŒŒì´í”„ë¼ì¸**: Load â†’ Split â†’ Embed â†’ Store â†’ Retrieve â†’ Generate\n",
    "3. **ì„ë² ë”©**: í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (Google Embedding)\n",
    "4. **Vector DB**: Chromaë¡œ ë¬¸ì„œ ì €ì¥ ë° ê²€ìƒ‰\n",
    "5. **LangChain**: RAG ì²´ì¸ êµ¬ì„±\n",
    "\n",
    "### ì‚¬ìš© API\n",
    "- **Google Gemini 2.5 Flash Lite** (ë¬´ë£Œ, Rate Limit íšŒí”¼ìš© ê¶Œì¥)\n",
    "- **Google Embedding** (ë¬´ë£Œ)\n",
    "- API Key: https://aistudio.google.com/app/apikey\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
