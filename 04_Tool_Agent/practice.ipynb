{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5êµì‹œ: Toolì„ ì´ìš©í•œ ê²€ìƒ‰ Agent ì œì‘\n",
    "\n",
    "## ì‹¤ìŠµ ëª©í‘œ\n",
    "- Function Calling ì›ë¦¬ ì´í•´\n",
    "- ê²€ìƒ‰ ë„êµ¬ ì—°ë™ Agent êµ¬í˜„\n",
    "- ë‚˜ë§Œì˜ Agent ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install langchain langchain-google-genai langchain-community google-generativeai duckduckgo-search -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import json\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools import tool\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key ì„¤ì •\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    GOOGLE_API_KEY = getpass(\"Google API Key: \")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "# Gemini ì„¤ì •\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Tavily API Key (ì„ íƒì‚¬í•­ - ì—†ìœ¼ë©´ DuckDuckGo ì‚¬ìš©)\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\", \"\")\n",
    "if not TAVILY_API_KEY:\n",
    "    print(\"Tavily API Keyê°€ ì—†ìŠµë‹ˆë‹¤. DuckDuckGo ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "if TAVILY_API_KEY:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "\n",
    "print(\"API Key ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Function Calling ì´í•´í•˜ê¸°\n",
    "\n",
    "### 2.1 ê¸°ë³¸ ì›ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini Function Calling ê¸°ë³¸ ì˜ˆì œ\n",
    "\n",
    "# ë„êµ¬(í•¨ìˆ˜) ì •ì˜ - Gemini í˜•ì‹\n",
    "get_weather_func = genai.protos.FunctionDeclaration(\n",
    "    name=\"get_weather\",\n",
    "    description=\"íŠ¹ì • ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ì— ì‚¬ìš©í•˜ì„¸ìš”.\",\n",
    "    parameters=genai.protos.Schema(\n",
    "        type=genai.protos.Type.OBJECT,\n",
    "        properties={\n",
    "            \"city\": genai.protos.Schema(\n",
    "                type=genai.protos.Type.STRING,\n",
    "                description=\"ë„ì‹œ ì´ë¦„ (ì˜ˆ: ì„œìš¸, ë¶€ì‚°, ì œì£¼)\"\n",
    "            )\n",
    "        },\n",
    "        required=[\"city\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "calculate_func = genai.protos.FunctionDeclaration(\n",
    "    name=\"calculate\",\n",
    "    description=\"ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê³„ì‚°ì´ í•„ìš”í•œ ì§ˆë¬¸ì— ì‚¬ìš©í•˜ì„¸ìš”.\",\n",
    "    parameters=genai.protos.Schema(\n",
    "        type=genai.protos.Type.OBJECT,\n",
    "        properties={\n",
    "            \"expression\": genai.protos.Schema(\n",
    "                type=genai.protos.Type.STRING,\n",
    "                description=\"ê³„ì‚°í•  ìˆ˜ì‹ (ì˜ˆ: 2 + 2, 100 * 5)\"\n",
    "            )\n",
    "        },\n",
    "        required=[\"expression\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# ë„êµ¬ ëª¨ìŒ\n",
    "tools_for_gemini = genai.protos.Tool(\n",
    "    function_declarations=[get_weather_func, calculate_func]\n",
    ")\n",
    "\n",
    "print(\"ë„êµ¬ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(f\"- get_weather: {get_weather_func.description}\")\n",
    "print(f\"- calculate: {calculate_func.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ì œ í•¨ìˆ˜ êµ¬í˜„ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"ë‚ ì”¨ ì •ë³´ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” API í˜¸ì¶œ)\"\"\"\n",
    "    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë‚ ì”¨ API í˜¸ì¶œ\n",
    "    weather_data = {\n",
    "        \"ì„œìš¸\": \"ë§‘ìŒ, ê¸°ì˜¨ 15Â°C, ìŠµë„ 45%\",\n",
    "        \"ë¶€ì‚°\": \"íë¦¼, ê¸°ì˜¨ 18Â°C, ìŠµë„ 60%\",\n",
    "        \"ì œì£¼\": \"êµ¬ë¦„ ë§ìŒ, ê¸°ì˜¨ 20Â°C, ìŠµë„ 70%\"\n",
    "    }\n",
    "    return weather_data.get(city, f\"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"ìˆ˜ì‹ ê³„ì‚°\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except:\n",
    "        return \"ê³„ì‚° ì˜¤ë¥˜\"\n",
    "\n",
    "# í•¨ìˆ˜ ë§¤í•‘\n",
    "available_functions = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"calculate\": calculate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Calling ì „ì²´ íë¦„ (Gemini)\n",
    "model = genai.GenerativeModel(\n",
    "    model_name='gemini-2.5-flash-lite',\n",
    "    tools=[tools_for_gemini]\n",
    ")\n",
    "\n",
    "def chat_with_tools(user_message):\n",
    "    print(f\"\\n[ì‚¬ìš©ì] {user_message}\")\n",
    "    \n",
    "    # 1ë‹¨ê³„: LLMì—ê²Œ ì§ˆë¬¸\n",
    "    response = model.generate_content(user_message)\n",
    "    \n",
    "    # 2ë‹¨ê³„: ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œì§€ í™•ì¸\n",
    "    if response.candidates[0].content.parts[0].function_call:\n",
    "        function_call = response.candidates[0].content.parts[0].function_call\n",
    "        function_name = function_call.name\n",
    "        function_args = dict(function_call.args)\n",
    "        \n",
    "        print(\"\\n[LLM] ë„êµ¬ í˜¸ì¶œ ê²°ì •:\")\n",
    "        print(f\"  - ë„êµ¬: {function_name}\")\n",
    "        print(f\"  - ì¸ì: {function_args}\")\n",
    "        \n",
    "        # 3ë‹¨ê³„: ì‹¤ì œ í•¨ìˆ˜ ì‹¤í–‰\n",
    "        function_response = available_functions[function_name](**function_args)\n",
    "        print(f\"  - ê²°ê³¼: {function_response}\")\n",
    "        \n",
    "        # 4ë‹¨ê³„: ê²°ê³¼ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "        response2 = model.generate_content([\n",
    "            user_message,\n",
    "            response.candidates[0].content,\n",
    "            genai.protos.Content(\n",
    "                parts=[genai.protos.Part(\n",
    "                    function_response=genai.protos.FunctionResponse(\n",
    "                        name=function_name,\n",
    "                        response={\"result\": function_response}\n",
    "                    )\n",
    "                )]\n",
    "            )\n",
    "        ])\n",
    "        answer = response2.text\n",
    "    else:\n",
    "        # ë„êµ¬ í˜¸ì¶œ ì—†ì´ ë°”ë¡œ ì‘ë‹µ\n",
    "        answer = response.text\n",
    "    \n",
    "    print(f\"\\n[AI] {answer}\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "chat_with_tools(\"ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_with_tools(\"123 ê³±í•˜ê¸° 456ì€?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_with_tools(\"ì•ˆë…•í•˜ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ê²€ìƒ‰ Agent ë§Œë“¤ê¸°\n",
    "\n",
    "### 3.1 ê²€ìƒ‰ ë„êµ¬ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DuckDuckGo ê²€ìƒ‰ ë„êµ¬ (ë¬´ë£Œ, API í‚¤ ë¶ˆí•„ìš”)\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# ê²€ìƒ‰ ë„êµ¬ ìƒì„±\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ê²€ìƒ‰\n",
    "print(\"[DuckDuckGo ê²€ìƒ‰ í…ŒìŠ¤íŠ¸]\")\n",
    "result = search_tool.invoke(\"2024ë…„ ë…¸ë²¨ìƒ ìˆ˜ìƒì\")\n",
    "print(result[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tavily ê²€ìƒ‰ (ë” ì •í™•, API í‚¤ í•„ìš”)\n",
    "if TAVILY_API_KEY:\n",
    "    from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "    \n",
    "    tavily_tool = TavilySearchResults(\n",
    "        max_results=3,\n",
    "        search_depth=\"basic\"\n",
    "    )\n",
    "    \n",
    "    print(\"[Tavily ê²€ìƒ‰ í…ŒìŠ¤íŠ¸]\")\n",
    "    result = tavily_tool.invoke(\"2024ë…„ AI íŠ¸ë Œë“œ\")\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"Tavily API Keyê°€ ì—†ì–´ DuckDuckGoë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ì»¤ìŠ¤í…€ ë„êµ¬ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool ë°ì½”ë ˆì´í„°ë¡œ ì»¤ìŠ¤í…€ ë„êµ¬ ë§Œë“¤ê¸°\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸ì— ì‚¬ìš©í•˜ì„¸ìš”.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„\")\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        expression: ê³„ì‚°í•  ìˆ˜ì‹ (ì˜ˆ: 2 + 2, 100 * 5, 2 ** 10)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì•ˆì „í•œ ê³„ì‚°ë§Œ í—ˆìš©\n",
    "        allowed_chars = set('0123456789+-*/().** ')\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return \"í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\"\n",
    "        result = eval(expression)\n",
    "        return f\"{expression} = {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"ê³„ì‚° ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def korean_to_english(text: str) -> str:\n",
    "    \"\"\"í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text: ë²ˆì—­í•  í•œêµ­ì–´ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # Geminië¡œ ë²ˆì—­\n",
    "    translate_model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
    "    response = translate_model.generate_content(\n",
    "        f\"Translate the following Korean text to English. Only provide the translation:\\n{text}\"\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "print(\"ì»¤ìŠ¤í…€ ë„êµ¬ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(f\"- get_current_time: {get_current_time.description}\")\n",
    "print(f\"- calculator: {calculator.description}\")\n",
    "print(f\"- korean_to_english: {korean_to_english.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„êµ¬ í…ŒìŠ¤íŠ¸\n",
    "print(\"í˜„ì¬ ì‹œê°„:\", get_current_time.invoke({}))\n",
    "print(\"ê³„ì‚°:\", calculator.invoke({\"expression\": \"2 ** 10\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 LangChain Agent êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„êµ¬ ëª©ë¡\n",
    "tools = [\n",
    "    search_tool,\n",
    "    get_current_time,\n",
    "    calculator,\n",
    "    korean_to_english\n",
    "]\n",
    "\n",
    "# LLM ì„¤ì • (Gemini)\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    temperature=0,\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë‹¹ì‹ ì€ ìœ ìš©í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ë„êµ¬ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "- ì›¹ ê²€ìƒ‰: ìµœì‹  ì •ë³´ë‚˜ ì‚¬ì‹¤ í™•ì¸ì´ í•„ìš”í•  ë•Œ\n",
    "- í˜„ì¬ ì‹œê°„: ë‚ ì§œ/ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸\n",
    "- ê³„ì‚°ê¸°: ìˆ˜í•™ ê³„ì‚°ì´ í•„ìš”í•  ë•Œ\n",
    "- ë²ˆì—­: í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•  ë•Œ\n",
    "\n",
    "í•­ìƒ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ê²€ìƒ‰ì„ í†µí•´ í™•ì¸í•˜ì„¸ìš”.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "# Agent ìƒì„± (tool_calling_agent ì‚¬ìš© - Gemini í˜¸í™˜)\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Agent ì‹¤í–‰ê¸° ìƒì„±\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,  # ì‹¤í–‰ ê³¼ì • ì¶œë ¥\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(\"Agent ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent í…ŒìŠ¤íŠ¸\n",
    "result = agent_executor.invoke({\"input\": \"ì§€ê¸ˆ ëª‡ ì‹œì•¼?\"})\n",
    "print(\"\\nìµœì¢… ë‹µë³€:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "result = agent_executor.invoke({\"input\": \"ìµœê·¼ OpenAI ê´€ë ¨ ë‰´ìŠ¤ ì•Œë ¤ì¤˜\"})\n",
    "print(\"\\nìµœì¢… ë‹µë³€:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³µí•© ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
    "result = agent_executor.invoke({\"input\": \"2ì˜ 20ìŠ¹ì´ ì–¼ë§ˆì•¼? ê·¸ë¦¬ê³  ê·¸ ê²°ê³¼ë¥¼ ì˜ì–´ë¡œ ë§í•´ì¤˜\"})\n",
    "print(\"\\nìµœì¢… ë‹µë³€:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Streamlit Agent ì•± ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile agent_chatbot.py\n",
    "\"\"\"\n",
    "Tool Agent ì±—ë´‡ (Gemini ë²„ì „)\n",
    "ì‹¤í–‰: streamlit run agent_chatbot.py\n",
    "\"\"\"\n",
    "import streamlit as st\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools import tool\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "st.set_page_config(page_title=\"AI Agent\", page_icon=\"ğŸ¤–\")\n",
    "\n",
    "st.title(\"AI Agent ì±—ë´‡ ğŸ¤–\")\n",
    "st.caption(\"ê²€ìƒ‰, ê³„ì‚°, ì‹œê°„ í™•ì¸ì´ ê°€ëŠ¥í•œ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤!\")\n",
    "\n",
    "# ì‚¬ì´ë“œë°”\n",
    "with st.sidebar:\n",
    "    api_key = st.text_input(\"Google API Key\", type=\"password\")\n",
    "    \n",
    "    st.divider()\n",
    "    st.markdown(\"### ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬\")\n",
    "    st.markdown(\"- ğŸ” ì›¹ ê²€ìƒ‰\")\n",
    "    st.markdown(\"- ğŸ• í˜„ì¬ ì‹œê°„\")\n",
    "    st.markdown(\"- ğŸ§® ê³„ì‚°ê¸°\")\n",
    "    \n",
    "    st.divider()\n",
    "    st.markdown(\"### ì§ˆë¬¸ ì˜ˆì‹œ\")\n",
    "    st.markdown(\"- ì˜¤ëŠ˜ AI ê´€ë ¨ ë‰´ìŠ¤ ì•Œë ¤ì¤˜\")\n",
    "    st.markdown(\"- ì§€ê¸ˆ ëª‡ ì‹œì•¼?\")\n",
    "    st.markdown(\"- 123 * 456 ê³„ì‚°í•´ì¤˜\")\n",
    "    \n",
    "    if st.button(\"ëŒ€í™” ì´ˆê¸°í™”\"):\n",
    "        st.session_state.messages = []\n",
    "        st.rerun()\n",
    "\n",
    "# ë„êµ¬ ì •ì˜\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return datetime.now().strftime(\"%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„\")\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. Args: expression: ê³„ì‚°í•  ìˆ˜ì‹\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except:\n",
    "        return \"ê³„ì‚° ì˜¤ë¥˜\"\n",
    "\n",
    "# Agent ì´ˆê¸°í™”\n",
    "@st.cache_resource\n",
    "def init_agent(_api_key):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = _api_key\n",
    "    \n",
    "    tools = [\n",
    "        DuckDuckGoSearchRun(),\n",
    "        get_current_time,\n",
    "        calculator\n",
    "    ]\n",
    "    \n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0,\n",
    "        google_api_key=_api_key\n",
    "    )\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"ë‹¹ì‹ ì€ ìœ ìš©í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "ì›¹ ê²€ìƒ‰, ì‹œê°„ í™•ì¸, ê³„ì‚° ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "í•­ìƒ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ])\n",
    "    \n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "    return AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "\n",
    "# ë©”ì‹œì§€ ì´ˆê¸°í™”\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# ì´ì „ ë©”ì‹œì§€ í‘œì‹œ\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.markdown(msg[\"content\"])\n",
    "\n",
    "# ìƒˆ ë©”ì‹œì§€ ì²˜ë¦¬\n",
    "if prompt := st.chat_input(\"ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”...\"):\n",
    "    if not api_key:\n",
    "        st.error(\"API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!\")\n",
    "        st.stop()\n",
    "    \n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "    \n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"ìƒê° ì¤‘...\"):\n",
    "            try:\n",
    "                agent_executor = init_agent(api_key)\n",
    "                result = agent_executor.invoke({\"input\": prompt})\n",
    "                answer = result[\"output\"]\n",
    "                st.markdown(answer)\n",
    "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            except Exception as e:\n",
    "                st.error(f\"ì˜¤ë¥˜: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. ë‚˜ë§Œì˜ Agent ë§Œë“¤ê¸° í”„ë¡œì íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ê¸°íšì„œ í…œí”Œë¦¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°íšì„œ í…œí”Œë¦¿\n",
    "project_template = \"\"\"\n",
    "# Agent ê¸°íšì„œ\n",
    "\n",
    "## 1. ê¸°ë³¸ ì •ë³´\n",
    "- Agent ì´ë¦„: \n",
    "- íŒ€ëª…/íŒ€ì›: \n",
    "- ì—­í• /ëª©ì : \n",
    "\n",
    "## 2. ì‚¬ìš© ë„êµ¬\n",
    "- [ ] ì›¹ ê²€ìƒ‰\n",
    "- [ ] í˜„ì¬ ì‹œê°„\n",
    "- [ ] ê³„ì‚°ê¸°\n",
    "- [ ] ì»¤ìŠ¤í…€ ë„êµ¬ 1: \n",
    "- [ ] ì»¤ìŠ¤í…€ ë„êµ¬ 2: \n",
    "\n",
    "## 3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "(Agentì˜ ì—­í• ê³¼ ì„±ê²©ì„ ì •ì˜)\n",
    "\n",
    "## 4. ì˜ˆìƒ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤\n",
    "ì‚¬ìš©ì: \n",
    "Agent: \n",
    "\n",
    "ì‚¬ìš©ì: \n",
    "Agent: \n",
    "\n",
    "## 5. ê¸°ëŒ€ íš¨ê³¼\n",
    "\"\"\"\n",
    "\n",
    "print(project_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ì˜ˆì‹œ: ì—¬í–‰ í”Œë˜ë„ˆ Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬í–‰ í”Œë˜ë„ˆ Agent ì˜ˆì‹œ\n",
    "\n",
    "@tool\n",
    "def search_tourist_spots(location: str) -> str:\n",
    "    \"\"\"íŠ¹ì • ì§€ì—­ì˜ ê´€ê´‘ì§€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        location: ê²€ìƒ‰í•  ì§€ì—­ (ì˜ˆ: ì„œìš¸, ì œì£¼, ë¶€ì‚°)\n",
    "    \"\"\"\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    return search.invoke(f\"{location} ì¸ê¸° ê´€ê´‘ì§€ ì¶”ì²œ\")\n",
    "\n",
    "@tool\n",
    "def search_restaurants(location: str, food_type: str = \"\") -> str:\n",
    "    \"\"\"íŠ¹ì • ì§€ì—­ì˜ ë§›ì§‘ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        location: ê²€ìƒ‰í•  ì§€ì—­\n",
    "        food_type: ìŒì‹ ì¢…ë¥˜ (ì„ íƒì‚¬í•­)\n",
    "    \"\"\"\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    query = f\"{location} ë§›ì§‘ ì¶”ì²œ\"\n",
    "    if food_type:\n",
    "        query += f\" {food_type}\"\n",
    "    return search.invoke(query)\n",
    "\n",
    "# ì—¬í–‰ í”Œë˜ë„ˆ Agent êµ¬ì„±\n",
    "travel_tools = [\n",
    "    search_tool,\n",
    "    search_tourist_spots,\n",
    "    search_restaurants,\n",
    "    get_current_time\n",
    "]\n",
    "\n",
    "travel_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì—¬í–‰ í”Œë˜ë„ˆ AIì…ë‹ˆë‹¤.\n",
    "\n",
    "ì—­í• :\n",
    "- ì—¬í–‰ ê³„íš ìˆ˜ë¦½ì„ ë„ì™€ì¤ë‹ˆë‹¤\n",
    "- ê´€ê´‘ì§€, ë§›ì§‘ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¶”ì²œí•©ë‹ˆë‹¤\n",
    "- ì—¬í–‰ ì¼ì •ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•©ë‹ˆë‹¤\n",
    "\n",
    "ìŠ¤íƒ€ì¼:\n",
    "- ì¹œê·¼í•˜ê³  ë°ì€ í†¤ìœ¼ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤\n",
    "- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
    "- êµ¬ì²´ì ì¸ ì •ë³´ì™€ í•¨ê»˜ ê°œì¸ì ì¸ íŒë„ ì œê³µí•©ë‹ˆë‹¤\n",
    "\n",
    "í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "travel_agent = create_tool_calling_agent(llm, travel_tools, travel_prompt)\n",
    "travel_executor = AgentExecutor(agent=travel_agent, tools=travel_tools, verbose=True)\n",
    "\n",
    "print(\"ì—¬í–‰ í”Œë˜ë„ˆ Agent ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬í–‰ í”Œë˜ë„ˆ í…ŒìŠ¤íŠ¸\n",
    "result = travel_executor.invoke({\"input\": \"ì œì£¼ë„ 2ë°•3ì¼ ì—¬í–‰ ê³„íš ì„¸ì›Œì¤˜\"})\n",
    "print(\"\\nìµœì¢… ë‹µë³€:\")\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 ë‚˜ë§Œì˜ Agent êµ¬í˜„í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ì—¬ê¸°ì— ë‚˜ë§Œì˜ Agentë¥¼ êµ¬í˜„í•˜ì„¸ìš”!\n",
    "\n",
    "# 1. ì»¤ìŠ¤í…€ ë„êµ¬ ì •ì˜\n",
    "@tool\n",
    "def my_custom_tool(query: str) -> str:\n",
    "    \"\"\"ë‚˜ë§Œì˜ ë„êµ¬ ì„¤ëª…\n",
    "    \n",
    "    Args:\n",
    "        query: ì…ë ¥ íŒŒë¼ë¯¸í„° ì„¤ëª…\n",
    "    \"\"\"\n",
    "    # ë„êµ¬ êµ¬í˜„\n",
    "    return \"ê²°ê³¼\"\n",
    "\n",
    "# 2. ë„êµ¬ ëª©ë¡\n",
    "my_tools = [\n",
    "    search_tool,\n",
    "    # my_custom_tool,\n",
    "]\n",
    "\n",
    "# 3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "my_system_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ [ì—­í• ]ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì—­í• :\n",
    "- \n",
    "\n",
    "ìŠ¤íƒ€ì¼:\n",
    "- \n",
    "\"\"\"\n",
    "\n",
    "# 4. Agent ìƒì„±\n",
    "# my_prompt = ChatPromptTemplate.from_messages([...])\n",
    "# my_agent = create_openai_functions_agent(llm, my_tools, my_prompt)\n",
    "# my_executor = AgentExecutor(agent=my_agent, tools=my_tools)\n",
    "\n",
    "# 5. í…ŒìŠ¤íŠ¸\n",
    "# result = my_executor.invoke({\"input\": \"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸\"})\n",
    "# print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì •ë¦¬\n",
    "\n",
    "### ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©\n",
    "\n",
    "1. **Function Calling**: LLMì´ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  í˜¸ì¶œí•˜ëŠ” ì›ë¦¬\n",
    "2. **Tool ì •ì˜**: name, description, parameters\n",
    "3. **LangChain Agent**: ë„êµ¬ + LLM + ì‹¤í–‰ê¸°\n",
    "4. **ì»¤ìŠ¤í…€ Tool**: @tool ë°ì½”ë ˆì´í„° ì‚¬ìš©ë²•\n",
    "\n",
    "### ì „ì²´ ìˆ˜ì—… ìš”ì•½\n",
    "\n",
    "| ì°¨ì‹œ | í•µì‹¬ ë‚´ìš© |\n",
    "|------|----------|\n",
    "| 1-2êµì‹œ | LLM ì›ë¦¬/í•œê³„ â†’ Agentic AI í•„ìš”ì„± |\n",
    "| 3êµì‹œ | Streamlit + API = ì›¹ì•± |\n",
    "| 4êµì‹œ | RAG = ê²€ìƒ‰ + LLM |\n",
    "| 5êµì‹œ | Tool = LLMì˜ í–‰ë™ ëŠ¥ë ¥ |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
